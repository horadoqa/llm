{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importa a biblioteca necessária\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Carrega o tokenizer e o modelo GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Função para gerar texto com o LLM\n",
    "def gerar_texto(prompt, max_length=100):\n",
    "    # Tokeniza o prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Gera texto baseado no prompt\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    \n",
    "    # Decodifica o texto gerado\n",
    "    texto_gerado = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return texto_gerado\n",
    "\n",
    "# Exemplo de uso\n",
    "prompt = \"A inteligência artificial está mudando o mundo de forma significativa\"\n",
    "texto_gerado = gerar_texto(prompt, max_length=150)\n",
    "\n",
    "print(\"Texto gerado:\")\n",
    "print(texto_gerado)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
